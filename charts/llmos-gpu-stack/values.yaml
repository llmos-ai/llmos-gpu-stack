nameOverride: ""
fullnameOverride: ""

global:
  ## @param global.imageRegistry Global Docker image registry
  ##
  imageRegistry: ""
  ## @param global.imagePullSecrets Global Docker registry secret names as an array
  ## e.g.
  ## imagePullSecrets:
  ##   - myRegistryKeySecretName
  ##
  imagePullSecrets: []
  imagePullPolicy: IfNotPresent

priorityClassNames:
  deviceManager: system-node-critical
  devicePlugin: system-node-critical

gpuStack:
  serviceAccount:
    # Specifies whether a service account should be created
    create: true
    # Automatically mount a ServiceAccount's API credentials?
    automount: true
    # Annotations to add to the service account
    annotations: {}
    # The name of the service account to use.
    # If not set and create is true, a name is generated using the fullname template
    name: ""

  deviceManager:
    replicas: 1

    image:
      repository: ghcr.io/llmos-ai/llmos-gpu-stack
      pullPolicy: Always
      # Overrides the image tag whose default is the chart appVersion.
      tag: "main-head"

    podAnnotations: {}
    podLabels: {}
    podSecurityContext: {}
    securityContext: {}

    service:
      type: ClusterIP
      port: 8080
      profilePort: 6060

    resources:
      requests:
        cpu: 200m
        memory: 450Mi
      limits:
        cpu: 1
        memory: 2Gi

    volumes: []
    volumeMounts: []
    nodeSelector: {}
    tolerations:
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
        operator: Exists
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
        operator: Exists
    affinity: {}

    # This is to setup the liveness and readiness probes more information can be found here: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
    livenessProbe:
      httpGet:
        path: /healthz
        port: http
        scheme: HTTP
      periodSeconds: 30
    readinessProbe:
      httpGet:
        path: /healthz
        port: http
        scheme: HTTP

crds:
  enabled: true

gpuOperator:
  enabled: true
gpu-operator:
  driver:
    enabled: false
  devicePlugin:
    enabled: false
  dcgmExporter:
    enabled: true
    serviceMonitor:
      enabled: false
  toolkit:
    env:
      - name: CONTAINERD_CONFIG
        value: /var/lib/rancher/k3s/agent/etc/containerd/config.toml
      - name: CONTAINERD_SOCKET
        value: /run/k3s/containerd/containerd.sock
      - name: CONTAINERD_RUNTIME_CLASS
        value: nvidia
      - name: CONTAINERD_SET_AS_DEFAULT
        value: "true"

volcano:
  enabled: true
  basic:
    image_pull_policy: IfNotPresent
    image_tag_version: "v1.10.0"
  custom:
    metrics_enable: false
    admission_enable: true
    admission_replicas: 1
    controller_enable: true
    controller_replicas: 1
    scheduler_enable: true
    scheduler_replicas: 1
    scheduler_config_override: |
      actions: "enqueue, allocate, backfill"
      tiers:
      - plugins:
        - name: priority
        - name: gang
          enablePreemptable: false
        - name: conformance
      - plugins:
        - name: overcommit
        - name: drf
          enablePreemptable: false
        - name: deviceshare
          arguments:
            deviceshare.VGPUEnable: true  # enable vgpu
        - name: predicates
        - name: proportion
        - name: nodeorder
        - name: binpack
    leader_elect_enable: false
    enabled_admissions: "/jobs/mutate,/jobs/validate,/podgroups/mutate,/pods/validate,/pods/mutate,/queues/mutate,/queues/validate"
    admission_resources:
      limits:
        cpu: 500m
        memory: 500Mi
    scheduler_resources:
      limits:
        cpu: 500m
        memory: 1Gi
    controller_resources:
      limits:
        cpu: 500m
        memory: 1Gi

devicePlugin:
  enabled: true
  image:
    repository: projecthami/volcano-vgpu-device-plugin
    tag: "v1.9.4"
    pullPolicy: IfNotPresent
  updateStrategy: "RollingUpdate"
  podAnnotations: {}
  podLabels: {}
  podSecurityContext: {}
  runtimeClassName: "nvidia"
  nodeSelector:
    gpustack.llmos.ai/gpu-node: "true"
  volumes: []
  volumeMounts: []
  tolerations:
    - key: volcano.sh/gpu-memory
      operator: Exists
      effect: NoSchedule
  affinity: {}
  splitCount: 10
  metrics:
    enabled: false
